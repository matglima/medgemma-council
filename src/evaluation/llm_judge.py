"""
LLM-as-Judge evaluation for clinical plan quality.

Uses an LLM to score clinical plans generated by the Council
on criteria like clinical accuracy, completeness, and safety.
"""

import re
from typing import Any, Callable, Dict, List


def generate_judging_prompt(
    patient_context: Dict[str, str],
    clinical_plan: str,
) -> str:
    """Generate a prompt for LLM-based clinical plan evaluation.

    Args:
        patient_context: Dict with patient information (e.g. chief_complaint, age).
        clinical_plan: The clinical plan text to evaluate.

    Returns:
        Formatted judging prompt asking the LLM to score the plan.
    """
    context_lines = "\n".join(
        f"  {key}: {value}" for key, value in patient_context.items()
    )

    return (
        f"You are an expert clinical evaluator. Rate the following clinical plan "
        f"on a scale of 1-5 for clinical accuracy, completeness, safety, and "
        f"evidence-based reasoning.\n\n"
        f"Patient Context:\n{context_lines}\n\n"
        f"Clinical Plan:\n{clinical_plan}\n\n"
        f"Provide your evaluation in the following format:\n"
        f"Score: <number>/5\n"
        f"Rationale: <your detailed rationale>\n"
    )


class LLMJudge:
    """Evaluates clinical plans using an LLM as a judge.

    Attributes:
        llm: A callable that takes a prompt string and returns a response
            in the format {"choices": [{"text": "..."}]} or a plain string.
    """

    def __init__(self, llm: Callable[..., Any]) -> None:
        """Initialize the LLM Judge.

        Args:
            llm: LLM callable for generating evaluations.
        """
        self.llm = llm

    def evaluate_plan(
        self,
        patient_context: Dict[str, str],
        clinical_plan: str,
    ) -> Dict[str, Any]:
        """Evaluate a single clinical plan.

        Args:
            patient_context: Dict with patient information.
            clinical_plan: The clinical plan to evaluate.

        Returns:
            Dict with 'score' (int) and 'rationale' (str) keys.
            On error, returns {'score': 0, 'rationale': '', 'error': str}.
        """
        try:
            prompt = generate_judging_prompt(patient_context, clinical_plan)
            response = self.llm(prompt)

            # Handle dict response format
            if isinstance(response, dict):
                text = response["choices"][0]["text"]
            else:
                text = str(response)

            score = self._extract_score(text)
            rationale = self._extract_rationale(text)

            return {"score": score, "rationale": rationale}

        except Exception as e:
            return {"score": 0, "rationale": "", "error": str(e)}

    def evaluate_batch(
        self,
        cases: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """Evaluate a batch of clinical plans.

        Args:
            cases: List of dicts, each with 'patient_context' and 'clinical_plan'.

        Returns:
            List of evaluation result dicts.
        """
        results = []
        for case in cases:
            result = self.evaluate_plan(
                patient_context=case["patient_context"],
                clinical_plan=case["clinical_plan"],
            )
            results.append(result)
        return results

    def _extract_score(self, text: str) -> int:
        """Extract a numeric score from LLM judge output.

        Supports formats like 'Score: 4/5' and 'Score: 4'.

        Args:
            text: LLM response text.

        Returns:
            Extracted score as int, or 0 if parsing fails.
        """
        # Try "Score: X/Y" format first
        match = re.search(r"[Ss]core:\s*(\d+)\s*/\s*\d+", text)
        if match:
            return int(match.group(1))

        # Try "Score: X" format
        match = re.search(r"[Ss]core:\s*(\d+)", text)
        if match:
            return int(match.group(1))

        return 0

    def _extract_rationale(self, text: str) -> str:
        """Extract the rationale from LLM judge output.

        Args:
            text: LLM response text.

        Returns:
            Extracted rationale string, or empty string if not found.
        """
        match = re.search(r"[Rr]ationale:\s*(.*)", text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return ""
