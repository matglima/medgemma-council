{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedGemma-Council: Multi-Agent Clinical Decision Support\n",
    "\n",
    "This notebook demonstrates the MedGemma-Council system -- a \"Council of Experts\" \n",
    "that debates clinical cases via a LangGraph state machine, powered by MedGemma 1.5 models.\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Ingestion -> Supervisor Route -> Specialists (parallel) -> Safety Check\n",
    "  -> [red flag] -> Emergency Synthesis -> END\n",
    "  -> [safe] -> Conflict Check\n",
    "    -> [conflict] -> Research (PubMed) -> Debate -> Conflict Check (loop, max 3)\n",
    "    -> [no conflict] -> Synthesis -> Final Plan\n",
    "```\n",
    "\n",
    "## Available Specialists (10 agents)\n",
    "- **Cardiology** (ACC/AHA), **Oncology** (NCCN), **Pediatrics** (AAP/WHO)\n",
    "- **Radiology** (vision-based), **Psychiatry** (APA/DSM-5-TR)\n",
    "- **Emergency Medicine** (ACLS/ATLS), **Dermatology** (AAD)\n",
    "- **Neurology** (AAN/AHA-ASA), **Endocrinology** (ADA/Endocrine Society)\n",
    "- **Research** (PubMed/MEDLINE literature retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the medgemma-council package\n",
    "# On Kaggle, the repo should be uploaded as a dataset or utility script\n",
    "import os\n",
    "\n",
    "# If running on Kaggle:\n",
    "REPO_PATH = \"/kaggle/working/medgemma-council\"\n",
    "if not os.path.exists(REPO_PATH):\n",
    "    # Fallback for local development\n",
    "    REPO_PATH = \".\"\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q langgraph langchain-core pydantic biopython datasets chromadb\n",
    "\n",
    "# Install the package itself\n",
    "!pip install -q -e {REPO_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(REPO_PATH, \"src\"))\n",
    "\n",
    "from graph import CouncilState, build_council_graph\n",
    "from utils.safety import scan_for_red_flags, redact_pii\n",
    "from utils.model_factory import ModelFactory\n",
    "print(\"Installation verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Tests (Verify Integrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full test suite to verify everything works\n",
    "# All 367 tests should pass in < 2 seconds (everything is mocked, no GPU needed)\n",
    "!cd {REPO_PATH} && python -m pytest tests/ -v --tb=short 2>&1 | tail -30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CLI-First Workflow (Recommended for Kaggle)\n",
    "\n",
    "The `council_cli` module provides the simplest way to run the council \n",
    "programmatically without any web framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CLI module\n",
    "sys.path.insert(0, REPO_PATH)\n",
    "from council_cli import run_council_cli, format_result, build_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Cardiology Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a cardiology case\n",
    "result = run_council_cli(\n",
    "    age=65,\n",
    "    sex=\"Male\",\n",
    "    chief_complaint=\"Chest pain radiating to left arm, onset 2 hours ago\",\n",
    "    history=\"Hypertension, Type 2 Diabetes, former smoker (quit 5 years ago)\",\n",
    "    medications=[\"Metformin 1000mg BID\", \"Lisinopril 20mg daily\", \"Aspirin 81mg daily\"],\n",
    "    vitals={\"bp\": \"160/95\", \"hr\": 92, \"temp\": 98.6, \"spo2\": 96, \"rr\": 18},\n",
    "    labs={\"troponin\": 0.08, \"bnp\": 450, \"creatinine\": 1.4, \"glucose\": 210},\n",
    ")\n",
    "\n",
    "# Display formatted results\n",
    "print(format_result(result, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Pediatrics Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_peds = run_council_cli(\n",
    "    age=5,\n",
    "    sex=\"Female\",\n",
    "    chief_complaint=\"High fever (103F) for 3 days with cough and poor appetite\",\n",
    "    history=\"No significant past medical history, vaccinations up to date\",\n",
    "    medications=[],\n",
    "    vitals={\"temp\": 103.0, \"hr\": 130, \"rr\": 28, \"spo2\": 94},\n",
    "    labs={\"wbc\": 18000, \"crp\": 45},\n",
    ")\n",
    "\n",
    "print(format_result(result_peds, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Multi-specialty Case (Oncology + Cardiology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_multi = run_council_cli(\n",
    "    age=58,\n",
    "    sex=\"Female\",\n",
    "    chief_complaint=\"Newly diagnosed breast cancer with pre-existing heart failure\",\n",
    "    history=\"HFrEF (LVEF 35%), NYHA Class II, breast mass found on screening mammography\",\n",
    "    medications=[\"Carvedilol 25mg BID\", \"Sacubitril/Valsartan 97/103mg BID\", \"Spironolactone 25mg\"],\n",
    "    vitals={\"bp\": \"110/70\", \"hr\": 68, \"spo2\": 97},\n",
    "    labs={\"bnp\": 890, \"troponin\": 0.02, \"lvef\": 35},\n",
    ")\n",
    "\n",
    "print(format_result(result_multi, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Neurology Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuro = run_council_cli(\n",
    "    age=72,\n",
    "    sex=\"Male\",\n",
    "    chief_complaint=\"Sudden onset right-sided weakness and slurred speech, 45 minutes ago\",\n",
    "    history=\"Atrial fibrillation (not on anticoagulation), Hypertension\",\n",
    "    medications=[\"Amlodipine 10mg daily\"],\n",
    "    vitals={\"bp\": \"185/110\", \"hr\": 88, \"rr\": 16, \"spo2\": 97},\n",
    "    labs={\"inr\": 1.0, \"glucose\": 140, \"platelets\": 220000},\n",
    ")\n",
    "\n",
    "print(format_result(result_neuro, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Endocrinology Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_endo = run_council_cli(\n",
    "    age=48,\n",
    "    sex=\"Female\",\n",
    "    chief_complaint=\"Uncontrolled diabetes with HbA1c 10.2%, recurrent DKA episodes\",\n",
    "    history=\"Type 1 Diabetes (20 years), Hashimoto thyroiditis, gastroparesis\",\n",
    "    medications=[\"Insulin glargine 40u daily\", \"Insulin lispro sliding scale\", \"Levothyroxine 100mcg\"],\n",
    "    vitals={\"bp\": \"128/78\", \"hr\": 98, \"temp\": 98.6, \"spo2\": 99},\n",
    "    labs={\"hba1c\": 10.2, \"glucose\": 320, \"tsh\": 4.8, \"creatinine\": 1.1},\n",
    ")\n",
    "\n",
    "print(format_result(result_endo, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with the Raw State\n",
    "\n",
    "For more control, you can work directly with the CouncilState."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build state manually\n",
    "state = build_state(\n",
    "    age=34,\n",
    "    sex=\"Male\",\n",
    "    chief_complaint=\"Severe anxiety, insomnia for 3 months, suicidal ideation\",\n",
    "    history=\"Major depressive disorder, generalized anxiety disorder\",\n",
    "    medications=[\"Sertraline 100mg daily\"],\n",
    ")\n",
    "\n",
    "# Inspect the state structure\n",
    "print(\"State keys:\", list(state.keys()))\n",
    "print(\"Patient context:\", state[\"patient_context\"])\n",
    "print(\"Red flag detected:\", state.get(\"red_flag_detected\", False))\n",
    "print(\"Emergency override:\", state.get(\"emergency_override\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for red flags BEFORE running the council\n",
    "from utils.safety import scan_for_red_flags\n",
    "\n",
    "flags = scan_for_red_flags(state[\"patient_context\"][\"chief_complaint\"])\n",
    "print(\"Red flags detected:\", flags[\"flagged\"])\n",
    "if flags[\"flagged\"]:\n",
    "    print(\"Flags:\", flags[\"flags\"])\n",
    "    print(\"Emergency message:\", flags[\"emergency_message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. JSON Output (for downstream processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get JSON output for programmatic use\n",
    "json_output = format_result(result, output_format=\"json\")\n",
    "parsed = json.loads(json_output)\n",
    "\n",
    "print(\"Final Plan:\", parsed[\"final_plan\"][:200], \"...\")\n",
    "print(\"Consensus:\", parsed[\"consensus_reached\"])\n",
    "print(\"Specialists consulted:\", list(parsed[\"agent_outputs\"].keys()))\n",
    "print(\"Red flag detected:\", parsed.get(\"red_flag_detected\", False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using Medical Images\n",
    "\n",
    "The RadiologyAgent and DermatologyAgent can process medical images \n",
    "using the MedGemma 1.5 4B multimodal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with images (paths should point to actual image files)\n",
    "# On Kaggle, images would be in /kaggle/input/your-dataset/\n",
    "\n",
    "# result_with_images = run_council_cli(\n",
    "#     age=72,\n",
    "#     sex=\"Male\",\n",
    "#     chief_complaint=\"Persistent cough, weight loss, hemoptysis\",\n",
    "#     history=\"40 pack-year smoking history\",\n",
    "#     image_paths=[\n",
    "#         \"/kaggle/input/chest-xrays/current_cxr.png\",\n",
    "#         \"/kaggle/input/chest-xrays/prior_cxr_6mo.png\",\n",
    "#     ],\n",
    "# )\n",
    "# print(format_result(result_with_images))\n",
    "\n",
    "print(\"Image processing requires MedGemma 1.5 4B model on GPU.\")\n",
    "print(\"Uncomment the code above when running on Kaggle with T4 GPUs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Loading (GPU Setup)\n",
    "\n",
    "On Kaggle with T4 GPUs, load the actual MedGemma models using \n",
    "`transformers` + `bitsandbytes` for 4-bit quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Model Loading (uncomment on Kaggle with T4 GPUs)\n",
    "#\n",
    "# import os\n",
    "# os.environ[\"MEDGEMMA_USE_REAL_MODELS\"] = \"true\"\n",
    "#\n",
    "# from utils.model_factory import ModelFactory\n",
    "# from utils.quantization import get_model_kwargs, detect_gpu_config\n",
    "#\n",
    "# # Check GPU availability\n",
    "# gpu_config = detect_gpu_config()\n",
    "# print(f\"GPUs detected: {gpu_config}\")\n",
    "#\n",
    "# # Create factory in real mode\n",
    "# factory = ModelFactory()\n",
    "#\n",
    "# # Load MedGemma-27B with 4-bit NF4 quantization (auto-split across 2xT4)\n",
    "# # Uses: BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\")\n",
    "# # Memory budget: max_memory={0: \"14GiB\", 1: \"14GiB\"}\n",
    "# text_model = factory.create_text_model()\n",
    "# print(\"Text model loaded (4-bit NF4, ~13.5 GB across 2xT4)\")\n",
    "#\n",
    "# # Load MedGemma 1.5 4B vision model (bfloat16 on single T4)\n",
    "# vision_model = factory.create_vision_model()\n",
    "# print(\"Vision model loaded (bfloat16, ~8 GB on single T4)\")\n",
    "\n",
    "print(\"Model loading requires Kaggle T4 GPU environment.\")\n",
    "print(\"Set MEDGEMMA_USE_REAL_MODELS=true to enable real model loading.\")\n",
    "print(\"In mock mode (default), all model calls return placeholder responses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Harness\n",
    "\n",
    "Run the council against standard medical QA benchmarks to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.benchmarks import load_medqa, load_pubmedqa, load_medmcqa, format_medqa_prompt\n",
    "from evaluation.evaluator import CouncilEvaluator\n",
    "from evaluation.metrics import compute_accuracy, generate_report\n",
    "\n",
    "# Preview benchmark data (uses HuggingFace datasets, mocked in tests)\n",
    "# medqa_items = load_medqa(limit=5)\n",
    "# print(f\"MedQA sample: {medqa_items[0]['question'][:100]}...\")\n",
    "# print(f\"Options: {medqa_items[0]['options']}\")\n",
    "# print(f\"Answer: {medqa_items[0]['answer']}\")\n",
    "\n",
    "print(\"Available benchmarks:\")\n",
    "print(\"  - MedQA (GBaker/MedQA-USMLE-4-options): 1.27k USMLE-style questions\")\n",
    "print(\"  - PubMedQA (qiaojin/PubMedQA): 1k yes/no/maybe questions\")\n",
    "print(\"  - MedMCQA (openlifescienceai/medmcqa): 194k with 21 subject tags\")\n",
    "print(\"\")\n",
    "print(\"CLI usage:\")\n",
    "print(\"  python -m evaluation.runner --benchmark medqa --limit 100\")\n",
    "print(\"  python -m evaluation.runner --benchmark medmcqa --specialty Cardiology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation programmatically (uncomment when models are loaded)\n",
    "#\n",
    "# from graph import build_council_graph\n",
    "# from evaluation.evaluator import CouncilEvaluator\n",
    "# from evaluation.benchmarks import load_medqa, format_medqa_prompt\n",
    "# from evaluation.metrics import compute_accuracy, generate_report\n",
    "#\n",
    "# graph = build_council_graph()\n",
    "# evaluator = CouncilEvaluator(graph=graph)\n",
    "#\n",
    "# items = load_medqa(limit=50)\n",
    "# results = []\n",
    "# for item in items:\n",
    "#     prompt = format_medqa_prompt(item)\n",
    "#     result = evaluator.evaluate_single(item[\"question\"], item[\"answer\"], prompt)\n",
    "#     results.append(result)\n",
    "#\n",
    "# report = generate_report(results, benchmark_name=\"medqa\")\n",
    "# print(f\"Accuracy: {report['accuracy']:.1%}\")\n",
    "# print(f\"Total: {report['total']}\")\n",
    "\n",
    "print(\"Evaluation requires loaded models. Uncomment when running on Kaggle GPUs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. PMC-Patients & LLM-as-Judge Evaluation\n",
    "\n",
    "Evaluate clinical plan quality using PMC-Patients cases and an LLM judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.pmc_patients import load_pmc_patients, format_pmc_patient_prompt\n",
    "from evaluation.retrieval_metrics import compute_mrr, compute_ndcg\n",
    "from evaluation.llm_judge import LLMJudge, generate_judging_prompt\n",
    "\n",
    "# Preview a judging prompt\n",
    "sample_prompt = generate_judging_prompt(\n",
    "    patient_context={\"chief_complaint\": \"chest pain\", \"age\": \"65\", \"sex\": \"Male\"},\n",
    "    clinical_plan=\"Admit to CCU. Serial troponins q6h. Start heparin drip. Cardiology consult.\",\n",
    ")\n",
    "print(\"=== Sample Judging Prompt ===\")\n",
    "print(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-as-Judge evaluation (uncomment when models are loaded)\n",
    "#\n",
    "# judge = LLMJudge(llm=text_model)\n",
    "#\n",
    "# # Evaluate a single plan\n",
    "# score = judge.evaluate_plan(\n",
    "#     patient_context={\"chief_complaint\": \"chest pain\", \"age\": \"65\"},\n",
    "#     clinical_plan=\"Admit to CCU. Start heparin drip. Cardiology consult.\",\n",
    "# )\n",
    "# print(f\"Score: {score['score']}/5\")\n",
    "# print(f\"Rationale: {score['rationale']}\")\n",
    "#\n",
    "# # Batch evaluation\n",
    "# cases = [\n",
    "#     {\"patient_context\": {\"chief_complaint\": \"chest pain\"}, \"clinical_plan\": \"Plan A...\"},\n",
    "#     {\"patient_context\": {\"chief_complaint\": \"headache\"}, \"clinical_plan\": \"Plan B...\"},\n",
    "# ]\n",
    "# batch_scores = judge.evaluate_batch(cases)\n",
    "# for i, s in enumerate(batch_scores):\n",
    "#     print(f\"Case {i+1}: {s['score']}/5\")\n",
    "\n",
    "print(\"LLM-as-Judge requires loaded models. Uncomment when running on Kaggle GPUs.\")\n",
    "print(\"\")\n",
    "print(\"Retrieval metrics available:\")\n",
    "print(\"  compute_mrr(results)    - Mean Reciprocal Rank\")\n",
    "print(\"  compute_ndcg(results)   - NDCG@k (default k=10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guideline Ingestion (RAG Pipeline)\n",
    "\n",
    "Ingest clinical guideline documents into the ChromaDB vector store for \n",
    "retrieval-augmented generation by specialist agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ingestion import GuidelineChunker, IngestionPipeline\n",
    "\n",
    "# Preview the chunker\n",
    "chunker = GuidelineChunker(chunk_size=512, chunk_overlap=64)\n",
    "sample_text = (\n",
    "    \"ACC/AHA Guideline for Chest Pain Evaluation: \"\n",
    "    \"Patients presenting with acute chest pain should receive an immediate \"\n",
    "    \"12-lead ECG within 10 minutes of arrival. Serial troponin measurements \"\n",
    "    \"should be obtained at 0 and 3 hours using high-sensitivity assays. \"\n",
    "    \"Risk stratification using HEART score is recommended for all patients.\"\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk_text(sample_text, source=\"acc_aha_chest_pain.pdf\")\n",
    "print(f\"Input text: {len(sample_text)} chars\")\n",
    "print(f\"Chunks produced: {len(chunks)}\")\n",
    "for chunk in chunks:\n",
    "    print(f\"  Chunk {chunk['chunk_index']}: {len(chunk['text'])} chars, source={chunk['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest guideline documents (uncomment when you have guideline files)\n",
    "#\n",
    "# pipeline = IngestionPipeline(\n",
    "#     persist_directory=\"data/vector_store/\",\n",
    "#     collection_name=\"guidelines\",\n",
    "#     chunk_size=512,\n",
    "#     chunk_overlap=64,\n",
    "# )\n",
    "#\n",
    "# # Ingest from directory (supports .pdf, .txt, .md)\n",
    "# pipeline.ingest_directory(\"data/reference_docs/\")\n",
    "# stats = pipeline.get_stats()\n",
    "# print(f\"Ingested: {stats}\")\n",
    "#\n",
    "# # Or via CLI:\n",
    "# # !python scripts/ingest_guidelines.py --input-dir data/reference_docs/ --chunk-size 512\n",
    "\n",
    "print(\"Guideline ingestion ready. Supports: .pdf, .txt, .md\")\n",
    "print(\"Place guideline files in data/reference_docs/ then run the pipeline.\")\n",
    "print(\"\")\n",
    "print(\"CLI usage:\")\n",
    "print(\"  python scripts/ingest_guidelines.py --input-dir data/reference_docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Gradio UI (Alternative to Streamlit)\n",
    "\n",
    "For interactive use on Kaggle (where Streamlit doesn't work well), \n",
    "use the Gradio interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Gradio if not already installed\n",
    "# !pip install -q gradio\n",
    "\n",
    "# Launch the Gradio interface\n",
    "# This will create an interactive UI in the notebook output\n",
    "#\n",
    "# import subprocess\n",
    "# subprocess.Popen([\"python\", os.path.join(REPO_PATH, \"app_gradio.py\")])\n",
    "\n",
    "print(\"To launch Gradio UI:\")\n",
    "print(f\"  python {os.path.join(REPO_PATH, 'app_gradio.py')}\")\n",
    "print(\"Or import and launch directly:\")\n",
    "print(\"  from app_gradio import create_interface\")\n",
    "print(\"  demo = create_interface()\")\n",
    "print(\"  demo.launch(share=True)  # share=True for Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Safety Guardrails Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.safety import scan_for_red_flags, redact_pii, add_disclaimer\n",
    "\n",
    "# Red flag detection\n",
    "test_cases = [\n",
    "    \"Patient denies suicidal ideation but reports self-harm behavior.\",\n",
    "    \"Lactate > 4, MAP < 65, suspected septic shock.\",\n",
    "    \"Patient stable, vitals within normal limits.\",\n",
    "    \"Acute ischemic stroke, onset 45 minutes ago.\",\n",
    "    \"Pulseless ventricular tachycardia, initiating CPR.\",\n",
    "]\n",
    "\n",
    "for text in test_cases:\n",
    "    result = scan_for_red_flags(text)\n",
    "    status = \"RED FLAG\" if result[\"flagged\"] else \"CLEAR\"\n",
    "    flags = \", \".join(result[\"flags\"]) if result[\"flags\"] else \"none\"\n",
    "    print(f\"[{status}] {text[:60]}... -> {flags}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"When red flags are detected in the graph, the safety_check node\")\n",
    "print(\"routes to emergency_synthesis, bypassing normal debate flow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PII redaction\n",
    "text_with_pii = (\n",
    "    \"Patient John Smith, SSN 123-45-6789, phone (555) 123-4567, \"\n",
    "    \"email john@hospital.com, MRN: 12345678, presents with chest pain.\"\n",
    ")\n",
    "\n",
    "print(\"Before redaction:\")\n",
    "print(text_with_pii)\n",
    "print(\"\\nAfter redaction:\")\n",
    "print(redact_pii(text_with_pii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Installation** -- `pip install -e .` for the medgemma-council package\n",
    "2. **CLI workflow** -- `run_council_cli()` for programmatic use\n",
    "3. **Multiple case types** -- Cardiology, Pediatrics, Multi-specialty, Neurology, Endocrinology\n",
    "4. **Safety guardrails** -- Red flag detection (with graph-level override), PII redaction, disclaimers\n",
    "5. **Output formats** -- Text (human-readable) and JSON (machine-readable)\n",
    "6. **GPU setup** -- `transformers` + `bitsandbytes` 4-bit NF4 quantization with `device_map=\"auto\"`\n",
    "7. **Evaluation harness** -- MedQA, PubMedQA, MedMCQA benchmarks\n",
    "8. **PMC-Patients + LLM-as-Judge** -- Clinical plan scoring with retrieval metrics (MRR, NDCG)\n",
    "9. **Guideline ingestion** -- RAG pipeline for clinical guidelines (PDF/TXT/MD -> ChromaDB)\n",
    "10. **Gradio UI** -- Interactive web interface for Kaggle\n",
    "\n",
    "For production use on Kaggle T4 GPUs, set `MEDGEMMA_USE_REAL_MODELS=true` \n",
    "and ensure the MedGemma model weights are available as a dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
