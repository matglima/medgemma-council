{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedGemma-Council: Multi-Agent Clinical Decision Support\n",
    "\n",
    "This notebook demonstrates the MedGemma-Council system -- a \"Council of Experts\" \n",
    "that debates clinical cases via a LangGraph state machine, powered by MedGemma 1.5 models.\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Ingestion -> Supervisor Route -> Specialists (parallel) -> Safety Check\n",
    "  -> [red flag] -> Emergency Synthesis -> END\n",
    "  -> [safe] -> Conflict Check\n",
    "    -> [conflict] -> Research (PubMed) -> Debate -> Conflict Check (loop, max 3)\n",
    "    -> [no conflict] -> Synthesis -> Final Plan\n",
    "```\n",
    "\n",
    "## Available Specialists (10 agents)\n",
    "- **Cardiology** (ACC/AHA), **Oncology** (NCCN), **Pediatrics** (AAP/WHO)\n",
    "- **Radiology** (vision-based), **Psychiatry** (APA/DSM-5-TR)\n",
    "- **Emergency Medicine** (ACLS/ATLS), **Dermatology** (AAD)\n",
    "- **Neurology** (AAN/AHA-ASA), **Endocrinology** (ADA/Endocrine Society)\n",
    "- **Research** (PubMed/MEDLINE literature retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "USERNAME = 'matglima'\n",
    "REPO_NAME = 'medgemma-council'\n",
    "\n",
    "# Create the full URL with credentials\n",
    "REPO_URL = f\"https://github.com/{USERNAME}/{REPO_NAME}.git\"\n",
    "\n",
    "# Check if the repository directory already exists\n",
    "if os.path.exists(REPO_NAME):\n",
    "    print(f\"Repository '{REPO_NAME}' already exists. Pulling latest changes...\")\n",
    "    !git -C {REPO_NAME} pull\n",
    "else:\n",
    "    print(f\"Cloning repository '{REPO_NAME}'...\")\n",
    "    !git clone {REPO_URL}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# If running on Kaggle:\n",
    "REPO_PATH = \"/kaggle/working/medgemma-council\"\n",
    "if not os.path.exists(REPO_PATH):\n",
    "    # Fallback for local development\n",
    "    REPO_PATH = \".\"\n",
    "\n",
    "# Ensure relative paths (data/vector_store, data/reference_docs) resolve inside repo\n",
    "os.chdir(REPO_PATH)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Install the package itself in editable mode\n",
    "!pip install -q -e {REPO_PATH}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(REPO_PATH, \"src\"))\n",
    "\n",
    "from graph import CouncilState, build_council_graph\n",
    "from utils.safety import scan_for_red_flags, redact_pii\n",
    "from utils.model_factory import ModelFactory\n",
    "print(\"Installation verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Tests (Verify Integrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full test suite to verify everything works\n",
    "# All 483 tests should pass in < 2 seconds (everything is mocked, no GPU needed)\n",
    "!cd {REPO_PATH} && python -m pytest tests/ -v --tb=short 2>&1 | tail -30\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading (GPU Setup)\n",
    "\n",
    "This cell auto-detects GPU availability and loads the MedGemma models when\n",
    "running on Kaggle with T4 GPUs. Without GPUs, the system falls back to mock\n",
    "mode with placeholder responses.\n",
    "\n",
    "**Important:** Run this cell before the clinical examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Fetch the secret token\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "# Authenticate\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.quantization import detect_gpu_config\n",
    "from utils.model_factory import ModelFactory\n",
    "\n",
    "# Auto-detect GPU and configure model loading\n",
    "try:\n",
    "    gpu_config = detect_gpu_config()\n",
    "    print(f\"GPU config: {gpu_config}\")\n",
    "\n",
    "    if gpu_config[\"gpu_count\"] > 0:\n",
    "        os.environ[\"MEDGEMMA_USE_REAL_MODELS\"] = \"true\"\n",
    "        # Explicitly pin default text model to 4B for Kaggle stability\n",
    "        os.environ[\"MEDGEMMA_TEXT_MODEL_ID\"] = \"google/medgemma-1.5-4b-it\"\n",
    "\n",
    "        factory = ModelFactory()\n",
    "\n",
    "        # Load default MedGemma 1.5 4B text model (official image-text-to-text pipeline path)\n",
    "        text_model = factory.create_text_model()\n",
    "        print(\"Text model loaded (MedGemma 1.5 4B default)\")\n",
    "        text_hf_map = getattr(getattr(getattr(text_model, 'pipeline', None), 'model', None), 'hf_device_map', None)\n",
    "        if isinstance(text_hf_map, dict):\n",
    "            used_devices = sorted({str(device) for device in text_hf_map.values()})\n",
    "            print(f\"Text pipeline device map uses: {used_devices}\")\n",
    "\n",
    "        # Load MedGemma 1.5 4B vision model\n",
    "        vision_model = factory.create_vision_model()\n",
    "        print(\"Vision model loaded (MedGemma 1.5 4B multimodal)\")\n",
    "        vision_hf_map = getattr(getattr(getattr(vision_model, 'pipeline', None), 'model', None), 'hf_device_map', None)\n",
    "        if isinstance(vision_hf_map, dict):\n",
    "            used_devices = sorted({str(device) for device in vision_hf_map.values()})\n",
    "            print(f\"Vision pipeline device map uses: {used_devices}\")\n",
    "\n",
    "        print(\"\\nReal models loaded. Examples below will use actual inference.\")\n",
    "    else:\n",
    "        print(\"No GPU detected. Running in mock mode.\")\n",
    "        print(\"All model calls will return placeholder responses.\")\n",
    "        print(\"To use real models, run this notebook on Kaggle with T4 GPUs enabled.\")\n",
    "except Exception as e:\n",
    "    print(f\"Model loading failed: {e}\")\n",
    "    print(\"Falling back to mock mode. Examples will return placeholder responses.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Bootstrap Guideline RAG Data (Recommended Before Examples)\n",
    "\n",
    "Populate `data/reference_docs/` and `data/vector_store/` early so specialist \n",
    "examples can use guideline retrieval context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once before examples: scrape + ingest guidelines\n",
    "try:\n",
    "    !cd {REPO_PATH} && python scripts/scrape_guidelines.py \\\n",
    "      --output-dir data/reference_docs \\\n",
    "      --vector-dir data/vector_store \\\n",
    "      --collection guidelines \\\n",
    "      --chunk-size 512 \\\n",
    "      --chunk-overlap 64\n",
    "\n",
    "    from tools.rag_tool import RAGTool\n",
    "    rag = RAGTool(persist_dir=\"data/vector_store\", reference_docs_dir=\"data/reference_docs\")\n",
    "    preview = rag.query(\"CardiologyAgent guideline recommendations for chest pain\", top_k=2)\n",
    "    print(f\"RAG bootstrap complete. Retrieved {len(preview)} preview chunks.\")\n",
    "except Exception as e:\n",
    "    print(f\"RAG bootstrap skipped/failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CLI-First Workflow (Recommended for Kaggle)\n",
    "\n",
    "The `council_cli` module provides the simplest way to run the council \n",
    "programmatically without any web framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CLI module\n",
    "sys.path.insert(0, REPO_PATH)\n",
    "from council_cli import run_council_cli, format_result, build_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Cardiology Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a cardiology case\n",
    "result = run_council_cli(\n",
    "    age=65,\n",
    "    sex=\"Male\",\n",
    "    chief_complaint=\"Chest pain radiating to left arm, onset 2 hours ago\",\n",
    "    history=\"Hypertension, Type 2 Diabetes, former smoker (quit 5 years ago)\",\n",
    "    medications=[\"Metformin 1000mg BID\", \"Lisinopril 20mg daily\", \"Aspirin 81mg daily\"],\n",
    "    vitals={\"bp\": \"160/95\", \"hr\": 92, \"temp\": 98.6, \"spo2\": 96, \"rr\": 18},\n",
    "    labs={\"troponin\": 0.08, \"bnp\": 450, \"creatinine\": 1.4, \"glucose\": 210},\n",
    ")\n",
    "\n",
    "# Display formatted results\n",
    "print(format_result(result, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Pediatrics Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_peds = run_council_cli(\n",
    "    age=5,\n",
    "    sex=\"Female\",\n",
    "    chief_complaint=\"High fever (103F) for 3 days with cough and poor appetite\",\n",
    "    history=\"No significant past medical history, vaccinations up to date\",\n",
    "    medications=[],\n",
    "    vitals={\"temp\": 103.0, \"hr\": 130, \"rr\": 28, \"spo2\": 94},\n",
    "    labs={\"wbc\": 18000, \"crp\": 45},\n",
    ")\n",
    "\n",
    "print(format_result(result_peds, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Multi-specialty Case (Oncology + Cardiology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_multi = run_council_cli(\n",
    "    age=58,\n",
    "    sex=\"Female\",\n",
    "    chief_complaint=\"Newly diagnosed breast cancer with pre-existing heart failure\",\n",
    "    history=\"HFrEF (LVEF 35%), NYHA Class II, breast mass found on screening mammography\",\n",
    "    medications=[\"Carvedilol 25mg BID\", \"Sacubitril/Valsartan 97/103mg BID\", \"Spironolactone 25mg\"],\n",
    "    vitals={\"bp\": \"110/70\", \"hr\": 68, \"spo2\": 97},\n",
    "    labs={\"bnp\": 890, \"troponin\": 0.02, \"lvef\": 35},\n",
    ")\n",
    "\n",
    "print(format_result(result_multi, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Neurology Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuro = run_council_cli(\n",
    "    age=72,\n",
    "    sex=\"Male\",\n",
    "    chief_complaint=\"Sudden onset right-sided weakness and slurred speech, 45 minutes ago\",\n",
    "    history=\"Atrial fibrillation (not on anticoagulation), Hypertension\",\n",
    "    medications=[\"Amlodipine 10mg daily\"],\n",
    "    vitals={\"bp\": \"185/110\", \"hr\": 88, \"rr\": 16, \"spo2\": 97},\n",
    "    labs={\"inr\": 1.0, \"glucose\": 140, \"platelets\": 220000},\n",
    ")\n",
    "\n",
    "print(format_result(result_neuro, output_format=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Endocrinology Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_endo = run_council_cli(\n",
    "    age=48,\n",
    "    sex=\"Female\",\n",
    "    chief_complaint=\"Uncontrolled diabetes with HbA1c 10.2%, recurrent DKA episodes\",\n",
    "    history=\"Type 1 Diabetes (20 years), Hashimoto thyroiditis, gastroparesis\",\n",
    "    medications=[\"Insulin glargine 40u daily\", \"Insulin lispro sliding scale\", \"Levothyroxine 100mcg\"],\n",
    "    vitals={\"bp\": \"128/78\", \"hr\": 98, \"temp\": 98.6, \"spo2\": 99},\n",
    "    labs={\"hba1c\": 10.2, \"glucose\": 320, \"tsh\": 4.8, \"creatinine\": 1.1},\n",
    ")\n",
    "\n",
     "print(format_result(result_endo, output_format=\"text\"))"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Example 6: PubMed Research Agent\n",
     "\n",
     "The ResearchAgent searches PubMed for evidence when specialists disagree."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
     "source": [
      "### Example 6: PubMed Research Agent (Triggered with force_research)\n",
      "\n",
      "# The ResearchAgent can be triggered in two ways:\n",
      "# 1. Automatically when specialists DISAGREE (conflict detected)\n",
      "# 2. Manually by setting force_research=True (for complex cases requiring evidence)\n",
      "\n",
      "# This case creates a genuine conflict between Oncology and Cardiology:\n",
      "# - Oncology wants to treat aggressive cancer with anthracycline chemotherapy\n",
      "# - Cardiology is concerned about cardiotoxicity in a patient with existing heart failure\n",
      "# We use force_research=True to ensure the research agent runs regardless of conflict.
      "\n",
      "# Set your PubMed email (required by NCBI)\n",
      "import os\n",
      "os.environ[\"ENTREZ_EMAIL\"] = \"your_email@example.com\"  # Replace with your email\n",
      "\n",
      "# Case: Aggressive lymphoma in a patient with heart failure\n",
      "# This creates a true clinical dilemma where guidelines may conflict\n",
      "# Use force_research=True to ensure the research agent is triggered\n",
      "result_research = run_council_cli(\n",
      "    age=58,\n",
      "    sex=\"Female\",\n",
      "    chief_complaint=\"Newly diagnosed diffuse large B-cell lymphoma. Oncology recommends R-CHOP chemotherapy including doxorubicin, but I have heart failure with reduced ejection fraction. What should I do?\",\n",
      "    history=\"Heart failure with reduced EF (LVEF 35%, diagnosed 2 years ago), Hypertension, Recently diagnosed DLBCL stage III\",\n",
      "    medications=[\"Carvedilol 25mg BID\", \"Sacubitril/Valsartan 97/103mg BID\", \"Spironolactone 25mg daily\"],\n",
      "    vitals={\"bp\": \"105/68\", \"hr\": 62, \"spo2\": 96},\n",
      "    labs={\"bnp\": 890, \"troponin\": 0.02, \"ldh\": 450, \"lvef\": 35},\n",
      "    force_research=True,  # Force research agent to run for this complex case\n",
      ")\n",
      "\n",
      "print(\"=== Council Analysis (Conflict Expected - Research Agent Should Trigger) ===\")\n",
      "print(f\"Conflict detected: {result_research.get('conflict_detected', False)}\")\n",
      "print(f\"Debate rounds: {result_research.get('iteration_count', 0)}\")\n",
      "print(f\"Research findings length: {len(result_research.get('research_findings', ''))}\")\n",
      "print(\"\\n\" + format_result(result_research, output_format=\"text\"))"
     ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Example 7: MedASR Audio Transcription\n",
     "\n",
     "The MedASR tool transcribes clinical audio dictations using Whisper."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
     "source": [
      "### MedASR Audio Transcription Example\n",
      "# Transcribe clinical audio and use it as input for the council.\n",
      "\n",
      "from tools.medasr import MedASRTool\n",
      "import urllib.request\n",
      "\n",
      "asr = MedASRTool()\n",
      "print(f\"Supported audio formats: {asr.supported_formats}\")\n",
      "\n",
      "# Download medical consultation audio from PriMock57 dataset (open source mock primary care consultations)\n",
      "# Source: https://github.com/babylonhealth/primock57 - CC BY 4.0\n",
      "patient_audio_url = \"https://github.com/babylonhealth/primock57/raw/refs/heads/main/audio/day1_consultation01_patient.wav\"\n",
      "\n",
      "audio_path = \"/tmp/consultation_patient.wav\"\n",
      "urllib.request.urlretrieve(patient_audio_url, audio_path)\n",
      "print(f\"Downloaded patient audio to {audio_path}\")\n",
      "\n",
      "# Transcribe the patient's audio\n",
      "transcription = asr.transcribe(audio_path)\n",
      "print(f\"\\nPatient transcription (first 300 chars):\\n{transcription[:300]}...\")\n",
      "\n",
      "# Now run the council using the transcribed patient complaint\n",
      "result_asr = run_council_cli(\n",
      "    age=35,\n",
      "    sex=\"Female\",\n",
      "    chief_complaint=transcription[:500],  # Use transcribed text as chief complaint\n",
      "    history=\"No significant past medical history\",\n",
      ")\n",
      "\n",
      "print(\"\\n=== Council Analysis from Audio Transcription ===\")\n",
      "print(format_result(result_asr, output_format=\"text\"))"
     ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Example 8: Multi-Turn Council Run\n",
     "\n",
     "Run the council iteratively, adding follow-up information between rounds."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Multi-turn example: Start with limited info, then add lab results\n",
     "\n",
     "# Round 1: Initial presentation\n",
     "result_round1 = run_council_cli(\n",
     "    age=58,\n",
     "    sex=\"Male\",\n",
     "    chief_complaint=\"Progressive dyspnea on exertion, bilateral leg swelling\",\n",
     "    history=\"Hypertension, diabetes\",\n",
     "    medications=[\"Metformin\", \"Lisinopril\"],\n",
     ")\n",
     "print(\"=== ROUND 1: Initial Assessment ===\")\n",
     "print(result_round1.get(\"final_plan\", \"No plan yet\")[:500])\n",
     "\n",
     "# Round 2: Add lab results that change the differential\n",
     "result_round2 = run_council_cli(\n",
     "    age=58,\n",
     "    sex=\"Male\",\n",
     "    chief_complaint=\"Progressive dyspnea on exertion, bilateral leg swelling. Labs: BNP 1200, Troponin 0.02, Creatinine 2.1\",\n",
     "    history=\"Hypertension, diabetes, CKD stage 3\",\n",
     "    medications=[\"Metformin\", \"Lisinopril\", \"Furosemide 40mg daily\"],\n",
     "    labs={\"bnp\": 1200, \"troponin\": 0.02, \"creatinine\": 2.1, \"egfr\": 35},\n",
     ")\n",
     "print(\"\\n=== ROUND 2: With Lab Results ===\")\n",
     "print(format_result(result_round2, output_format=\"text\"))"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 5. Working with the Raw State\n",
     "\n",
     "For more control, you can work directly with the CouncilState."
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build state manually\n",
    "state = build_state(\n",
    "    age=34,\n",
    "    sex=\"Male\",\n",
    "    chief_complaint=\"Severe anxiety, insomnia for 3 months, suicidal ideation\",\n",
    "    history=\"Major depressive disorder, generalized anxiety disorder\",\n",
    "    medications=[\"Sertraline 100mg daily\"],\n",
    ")\n",
    "\n",
    "# Inspect the state structure\n",
    "print(\"State keys:\", list(state.keys()))\n",
    "print(\"Patient context:\", state[\"patient_context\"])\n",
    "print(\"Red flag detected:\", state.get(\"red_flag_detected\", False))\n",
    "print(\"Emergency override:\", state.get(\"emergency_override\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for red flags BEFORE running the council\n",
    "from utils.safety import scan_for_red_flags\n",
    "\n",
    "flags = scan_for_red_flags(state[\"patient_context\"][\"chief_complaint\"])\n",
    "print(\"Red flags detected:\", flags[\"flagged\"])\n",
    "if flags[\"flagged\"]:\n",
    "    print(\"Flags:\", flags[\"flags\"])\n",
    "    print(\"Emergency message:\", flags[\"emergency_message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. JSON Output (for downstream processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get JSON output for programmatic use\n",
    "json_output = format_result(result, output_format=\"json\")\n",
    "parsed = json.loads(json_output)\n",
    "\n",
    "print(\"Final Plan:\", parsed[\"final_plan\"][:200], \"...\")\n",
    "print(\"Consensus:\", parsed[\"consensus_reached\"])\n",
    "print(\"Specialists consulted:\", list(parsed[\"agent_outputs\"].keys()))\n",
    "print(\"Red flag detected:\", parsed.get(\"red_flag_detected\", False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Medical Images\n",
    "\n",
    "The RadiologyAgent and DermatologyAgent can process medical images \n",
    "using the MedGemma 1.5 4B multimodal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
    "source": [
     "# Example with images - downloads a chest X-ray from Wikipedia\n",
     "import urllib.request\n",
     "\n",
     "cxr_path = \"/tmp/chest_xray_pa.png\"\n",
     "urllib.request.urlretrieve(\n",
     "    \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\",\n",
     "    cxr_path\n",
     ")\n",
     "print(f\"Downloaded chest X-ray to {cxr_path}\")\n",
     "\n",
     "result_with_images = run_council_cli(\n",
     "    age=72,\n",
     "    sex=\"Male\",\n",
     "    chief_complaint=\"Persistent cough, weight loss, hemoptysis\",\n",
     "    history=\"40 pack-year smoking history\",\n",
     "    image_paths=[cxr_path],\n",
     ")\n",
     "\n",
     "print(format_result(result_with_images, output_format=\"text\"))"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Harness\n",
    "\n",
    "Run the council against standard medical QA benchmarks to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.benchmarks import load_medqa, load_pubmedqa, load_medmcqa, format_medqa_prompt\n",
    "from evaluation.evaluator import CouncilEvaluator\n",
    "from evaluation.metrics import compute_accuracy, generate_report\n",
    "\n",
    "# Preview benchmark data (uses HuggingFace datasets, mocked in tests)\n",
    "# medqa_items = load_medqa(limit=5)\n",
    "# print(f\"MedQA sample: {medqa_items[0]['question'][:100]}...\")\n",
    "# print(f\"Options: {medqa_items[0]['options']}\")\n",
    "# print(f\"Answer: {medqa_items[0]['answer']}\")\n",
    "\n",
    "print(\"Available benchmarks:\")\n",
    "print(\"  - MedQA (GBaker/MedQA-USMLE-4-options): 1.27k USMLE-style questions\")\n",
    "print(\"  - PubMedQA (qiaojin/PubMedQA): 1k yes/no/maybe questions\")\n",
    "print(\"  - MedMCQA (openlifescienceai/medmcqa): 194k with 21 subject tags\")\n",
    "print(\"\")\n",
    "print(\"CLI usage:\")\n",
    "print(\"  python -m evaluation.runner --benchmark medqa --limit 100\")\n",
    "print(\"  python -m evaluation.runner --benchmark medmcqa --specialty Cardiology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation programmatically (uncomment when models are loaded)\n",
    "#\n",
    "# from graph import build_council_graph\n",
    "# from evaluation.evaluator import CouncilEvaluator\n",
    "# from evaluation.benchmarks import load_medqa\n",
    "# from evaluation.metrics import generate_report\n",
    "#\n",
    "# graph = build_council_graph()\n",
    "# evaluator = CouncilEvaluator(graph=graph)\n",
    "#\n",
    "# items = load_medqa(limit=50)\n",
    "# results = evaluator.evaluate_batch(items)\n",
    "#\n",
    "# report = generate_report(results, benchmark_name=\"medqa\")\n",
    "# print(f\"Accuracy: {report['accuracy']:.1%}\")\n",
    "# print(f\"Total: {report['total']}\")\n",
    "\n",
    "print(\"Evaluation requires loaded models. Uncomment when running on Kaggle GPUs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. PMC-Patients & LLM-as-Judge Evaluation\n",
    "\n",
    "Evaluate clinical plan quality using PMC-Patients cases and an LLM judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.pmc_patients import load_pmc_patients, format_pmc_patient_prompt\n",
    "from evaluation.retrieval_metrics import compute_mrr, compute_ndcg\n",
    "from evaluation.llm_judge import LLMJudge, generate_judging_prompt\n",
    "\n",
    "# Preview a judging prompt\n",
    "sample_prompt = generate_judging_prompt(\n",
    "    patient_context={\"chief_complaint\": \"chest pain\", \"age\": \"65\", \"sex\": \"Male\"},\n",
    "    clinical_plan=\"Admit to CCU. Serial troponins q6h. Start heparin drip. Cardiology consult.\",\n",
    ")\n",
    "print(\"=== Sample Judging Prompt ===\")\n",
    "print(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-as-Judge evaluation (uncomment when models are loaded)\n",
    "#\n",
    "# judge = LLMJudge(llm=text_model)\n",
    "#\n",
    "# # Evaluate a single plan\n",
    "# score = judge.evaluate_plan(\n",
    "#     patient_context={\"chief_complaint\": \"chest pain\", \"age\": \"65\"},\n",
    "#     clinical_plan=\"Admit to CCU. Start heparin drip. Cardiology consult.\",\n",
    "# )\n",
    "# print(f\"Score: {score['score']}/5\")\n",
    "# print(f\"Rationale: {score['rationale']}\")\n",
    "#\n",
    "# # Batch evaluation\n",
    "# cases = [\n",
    "#     {\"patient_context\": {\"chief_complaint\": \"chest pain\"}, \"clinical_plan\": \"Plan A...\"},\n",
    "#     {\"patient_context\": {\"chief_complaint\": \"headache\"}, \"clinical_plan\": \"Plan B...\"},\n",
    "# ]\n",
    "# batch_scores = judge.evaluate_batch(cases)\n",
    "# for i, s in enumerate(batch_scores):\n",
    "#     print(f\"Case {i+1}: {s['score']}/5\")\n",
    "\n",
    "print(\"LLM-as-Judge requires loaded models. Uncomment when running on Kaggle GPUs.\")\n",
    "print(\"\")\n",
    "print(\"Retrieval metrics available:\")\n",
    "print(\"  compute_mrr(results)    - Mean Reciprocal Rank\")\n",
    "print(\"  compute_ndcg(results)   - NDCG@k (default k=10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guideline Ingestion (RAG Pipeline)\n",
    "\n",
    "Ingest clinical guideline documents into the ChromaDB vector store for \n",
    "retrieval-augmented generation by specialist agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape specialty guideline sources and ingest into ChromaDB\n",
    "# This bootstraps data/reference_docs/ and data/vector_store/\n",
    "!cd {REPO_PATH} && python scripts/scrape_guidelines.py \\\n",
    "  --output-dir data/reference_docs \\\n",
    "  --vector-dir data/vector_store \\\n",
    "  --collection guidelines \\\n",
    "  --chunk-size 512 \\\n",
    "  --chunk-overlap 64\n",
    "\n",
    "# Optional quick sanity check: retrieve chunks for chest pain\n",
    "from tools.rag_tool import RAGTool\n",
    "rag = RAGTool(persist_dir=\"data/vector_store\", reference_docs_dir=\"data/reference_docs\")\n",
    "chunks = rag.query(\"CardiologyAgent guideline recommendations for chest pain\", top_k=3)\n",
    "print(f\"Retrieved {len(chunks)} chunks\")\n",
    "for idx, chunk in enumerate(chunks[:2], 1):\n",
    "    print(f\"\\nChunk {idx} source: {chunk.get('source')} | score: {chunk.get('score')}\")\n",
    "    print(chunk.get('text', '')[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional advanced usage: ingest your own custom guideline files\n",
    "# (if you added additional PDFs/TXT/MD files to data/reference_docs)\n",
    "\n",
    "from tools.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    persist_dir=\"data/vector_store\",\n",
    "    collection_name=\"guidelines\",\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=64,\n",
    ")\n",
    "\n",
    "custom_chunks = pipeline.ingest_directory(\"data/reference_docs\")\n",
    "stats = pipeline.get_stats()\n",
    "print(f\"Custom ingestion chunks: {custom_chunks}\")\n",
    "print(f\"Collection stats: {stats}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Gradio UI (Alternative to Streamlit)\n",
    "\n",
    "For interactive use on Kaggle (where Streamlit doesn't work well), \n",
    "use the Gradio interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Gradio if not already installed\n",
    "# !pip install -q gradio\n",
    "\n",
    "# Launch the Gradio interface\n",
    "# This will create an interactive UI in the notebook output\n",
    "\n",
    "from app_gradio import build_gradio_app\n",
    "\n",
    "# Build and launch with share=True for Kaggle (creates public link)\n",
    "# Use a different port since 7860 may be blocked on Kaggle\n",
    "demo = build_gradio_app()\n",
    "demo.launch(share=True, server_port=7979)\n",
    "\n",
    "# Alternative: Run via subprocess if you prefer\n",
    "# import subprocess\n",
    "# subprocess.Popen([\"python\", os.path.join(REPO_PATH, \"app_gradio.py\"), \"--port\", \"7979\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Safety Guardrails Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.safety import scan_for_red_flags, redact_pii, add_disclaimer\n",
    "\n",
    "# Red flag detection\n",
    "test_cases = [\n",
    "    \"Patient denies suicidal ideation but reports self-harm behavior.\",\n",
    "    \"Lactate > 4, MAP < 65, suspected septic shock.\",\n",
    "    \"Patient stable, vitals within normal limits.\",\n",
    "    \"Acute ischemic stroke, onset 45 minutes ago.\",\n",
    "    \"Pulseless ventricular tachycardia, initiating CPR.\",\n",
    "]\n",
    "\n",
    "for text in test_cases:\n",
    "    result = scan_for_red_flags(text)\n",
    "    status = \"RED FLAG\" if result[\"flagged\"] else \"CLEAR\"\n",
    "    flags = \", \".join(result[\"flags\"]) if result[\"flags\"] else \"none\"\n",
    "    print(f\"[{status}] {text[:60]}... -> {flags}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"When red flags are detected in the graph, the safety_check node\")\n",
    "print(\"routes to emergency_synthesis, bypassing normal debate flow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PII redaction\n",
    "text_with_pii = (\n",
    "    \"Patient John Smith, SSN 123-45-6789, phone (555) 123-4567, \"\n",
    "    \"email john@hospital.com, MRN: 12345678, presents with chest pain.\"\n",
    ")\n",
    "\n",
    "print(\"Before redaction:\")\n",
    "print(text_with_pii)\n",
    "print(\"\\nAfter redaction:\")\n",
    "print(redact_pii(text_with_pii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Installation** -- `pip install -e .` for the medgemma-council package\n",
    "2. **Tests** -- Full test suite verification\n",
    "3. **GPU setup** -- Auto-detected GPUs and loaded MedGemma 1.5 4B as default text/vision models\n",
    "4. **CLI workflow** -- `run_council_cli()` for programmatic use\n",
    "5. **Multiple case types** -- Cardiology, Pediatrics, Multi-specialty, Neurology, Endocrinology\n",
    "6. **Safety guardrails** -- Red flag detection (with graph-level override), PII redaction, disclaimers\n",
    "7. **Output formats** -- Text (human-readable) and JSON (machine-readable)\n",
    "8. **Evaluation harness** -- MedQA, PubMedQA, MedMCQA benchmarks\n",
    "9. **PMC-Patients + LLM-as-Judge** -- Clinical plan scoring with retrieval metrics (MRR, NDCG)\n",
    "10. **Guideline ingestion** -- scraped + ingested specialist guideline corpus for RAG retrieval\n",
    "11. **Gradio UI** -- Interactive web interface for Kaggle\n",
    "\n",
    "For production use on Kaggle T4 GPUs, ensure the MedGemma model weights are \n",
    "available as a dataset. The notebook auto-detects GPUs and loads real models when available.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
